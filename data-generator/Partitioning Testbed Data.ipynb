{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_table(nrows, IDstart=1, P1start=1, ncols=1 ):\n",
    "    \"\"\"\n",
    "     Generate table which contain [ID,P1, ..] columns\n",
    "     - nrows: number of rows per table\n",
    "     - ncols: number of columns\n",
    "     - IDstart: starting sequence for ID column\n",
    "     - P1start: starting number for P1 column\n",
    "     \n",
    "     return generated table `table1`\n",
    "    \"\"\"\n",
    "    subjID = range(IDstart, nrows+IDstart)\n",
    "    data = {\"ID\": subjID}\n",
    "    for j in range(1, ncols+1):\n",
    "        P = [\"V_\"  + str(j) + \"-\" + str(i) for i in range(P1start, P1start + nrows)]\n",
    "        if j < 10:\n",
    "            data[\"P0\" + str(j) ] =  P\n",
    "        else:\n",
    "            data[\"P\" + str(j) ] =  P\n",
    "    \n",
    "    table1 = pd.DataFrame(data)\n",
    "    return table1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Virtical Partitioning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Without Duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrows = [1000, 3000, 10000, 50000, 100000]\n",
    "for nrow in nrows:      \n",
    "    subprocess.check_call('mkdir -p ../data/partitioning/vertical_without_dup_best_case/'+ str(int(nrow/1000)) + 'k_rows', shell=True)    \n",
    "    table1 = generate_table_multi_col(nrow, ncols=30)\n",
    "    columns = list(table1.columns)  \n",
    "    columns = sorted(columns)\n",
    "    columns.remove(\"ID\")\n",
    "    \n",
    "    part1 = table1[[\"ID\"] + columns[:int(len(columns)/2)]]\n",
    "    part2 = table1[[\"ID\"] + columns[int(len(columns)/2):]]\n",
    "    \n",
    "    part1.to_csv('../data/partitioning/vertical_without_dup_best_case/'+ str(int(nrow/1000)) + 'k_rows/table1.csv', index=False )\n",
    "    part2.to_csv('../data/partitioning/vertical_without_dup_best_case/'+ str(int(nrow/1000)) + 'k_rows/table2.csv', index=False )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Worst Case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrows = [1000, 3000, 10000, 50000, 100000]\n",
    "for nrow in nrows:      \n",
    "    subprocess.check_call('mkdir -p ../data/partitioning/vertical_without_dup_worst_case/'+ str(int(nrow/1000)) + 'k_rows', shell=True)    \n",
    "    table1 = generate_table_multi_col(nrow, ncols=30)\n",
    "    columns = list(table1.columns)\n",
    "    columns = sorted(columns)\n",
    "    columns.remove(\"ID\")\n",
    "    for i in range(0, len(columns)):\n",
    "        part1 = table1[[\"ID\", columns[i]]]        \n",
    "        part1.to_csv('../data/partitioning/vertical_without_dup_worst_case/'+ str(int(nrow/1000)) + 'k_rows/table'+str(i) + '.csv', index=False )        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With Duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrows = [1000, 3000, 10000, 50000, 100000]\n",
    "for nrow in nrows:      \n",
    "    subprocess.check_call('mkdir -p ../data/partitioning/vertical_with_dup_best_case/'+ str(int(nrow/1000)) + 'k_rows', shell=True)    \n",
    "    table1 = generate_table_multi_col(nrow, ncols=30)\n",
    "    columns = list(table1.columns)\n",
    "    columns = sorted(columns)\n",
    "    columns.remove(\"ID\")\n",
    "    \n",
    "    part1 = table1[[\"ID\"] + columns[:int(len(columns)/2)+1]]\n",
    "    part2 = table1[[\"ID\"] + columns[int(len(columns)/2)-1:]]\n",
    "    \n",
    "    part1.to_csv('../data/partitioning/vertical_with_dup_best_case/'+ str(int(nrow/1000)) + 'k_rows/table1.csv', index=False )\n",
    "    part2.to_csv('../data/partitioning/vertical_with_dup_best_case/'+ str(int(nrow/1000)) + 'k_rows/table2.csv', index=False )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Worst Case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrows = [1000, 3000, 10000, 50000, 100000]\n",
    "for nrow in nrows:\n",
    "    subprocess.check_call('mkdir -p ../data/partitioning/vertical_with_dup_worst_case/'+ str(int(nrow/1000)) + 'k_rows', shell=True)    \n",
    "    table1 = generate_table_multi_col(nrow, ncols=30)\n",
    "    columns = list(table1.columns)\n",
    "    columns = sorted(columns)\n",
    "    columns.remove(\"ID\")\n",
    "    for i in range(0, len(columns)):\n",
    "        if i+1 < len(columns):\n",
    "            part1 = table1[[\"ID\", columns[i], columns[i+1]]] \n",
    "        else:\n",
    "            part1 = table1[[\"ID\", columns[0], columns[i]]] \n",
    "            \n",
    "        part1.to_csv('../data/partitioning/vertical_with_dup_worst_case/'+ str(int(nrow/1000)) + 'k_rows/table'+str(i) + '.csv', index=False )        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Horizontal Partitioning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Without Duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrows = [1000, 3000, 10000, 50000, 100000]\n",
    "for nrow in nrows:      \n",
    "    subprocess.check_call('mkdir -p ../data/partitioning/horizontal_without_dup_best_case/'+ str(int(nrow/1000)) + 'k_rows', shell=True)    \n",
    "    table1 = generate_table_multi_col(nrow, ncols=30)   \n",
    "    \n",
    "    part1 = table1.head(int(nrow/2))\n",
    "    part2 = table1.tail(int(nrow/2))\n",
    "    \n",
    "    part1.to_csv('../data/partitioning/horizontal_without_dup_best_case/'+ str(int(nrow/1000)) + 'k_rows/table1.csv', index=False )\n",
    "    part2.to_csv('../data/partitioning/horizontal_without_dup_best_case/'+ str(int(nrow/1000)) + 'k_rows/table2.csv', index=False )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Worst Case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrows = [1000, 3000, 10000, 50000, 100000]\n",
    "for nrow in nrows:      \n",
    "    subprocess.check_call('mkdir -p ../data/partitioning/horizontal_without_dup_worst_case/'+ str(int(nrow/1000)) + 'k_rows', shell=True)    \n",
    "    table1 = generate_table_multi_col(nrow, ncols=30)\n",
    "    part_rows = 0.1 * nrow  # 10%\n",
    "    nfiles = nrow/part_rows\n",
    "    for i in range(0, int(nfiles)):\n",
    "        part1 = table1.iloc[list(range(i,int(i+part_rows)))]\n",
    "        part1.to_csv('../data/partitioning/horizontal_without_dup_worst_case/'+ str(int(nrow/1000)) + 'k_rows/table'+str(i) + '.csv', index=False )        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With Duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrows = [1000, 3000, 10000, 50000, 100000]\n",
    "for nrow in nrows:      \n",
    "    subprocess.check_call('mkdir -p ../data/partitioning/horizontal_with_dup_best_case/'+ str(int(nrow/1000)) + 'k_rows', shell=True)    \n",
    "    table1 = generate_table_multi_col(nrow, ncols=30)\n",
    "    \n",
    "    part1 = table1.head(int(nrow/2 + nrow * 0.15))\n",
    "    part2 = table1.tail(int(nrow/2 + nrow * 0.15))\n",
    "    \n",
    "    part1.to_csv('../data/partitioning/horizontal_with_dup_best_case/'+ str(int(nrow/1000)) + 'k_rows/table1.csv', index=False )\n",
    "    part2.to_csv('../data/partitioning/horizontal_with_dup_best_case/'+ str(int(nrow/1000)) + 'k_rows/table2.csv', index=False )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Worst Case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrows = [1000, 3000, 10000, 50000, 100000]\n",
    "for nrow in nrows:      \n",
    "    subprocess.check_call('mkdir -p ../data/partitioning/horizontal_with_dup_worst_case/'+ str(int(nrow/1000)) + 'k_rows', shell=True)    \n",
    "    table1 = generate_table_multi_col(nrow, ncols=30)\n",
    "    part_rows = 0.1 * nrow  # 10%\n",
    "    nfiles = nrow/part_rows\n",
    "    for i in range(0, int(nfiles)):\n",
    "        if i+part_rows + part_rows * 0.1 > nrow: # 10% duplicate\n",
    "            part1 = table1.iloc[list(range(i,nrow))]\n",
    "        else:\n",
    "            part1 = table1.iloc[list(range(i,int(i+part_rows)))]\n",
    "        part1.to_csv('../data/partitioning/horizontal_with_dup_worst_case/'+ str(int(nrow/1000)) + 'k_rows/table'+str(i) + '.csv', index=False )        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
